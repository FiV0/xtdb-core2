= CURRENT_TIMESTAMP as DB State

This document is written in response to link:bases.adoc[bases.adoc] and to make some of my thinking explicit as we reach the next phase, during we will start looking at resolving this in earnest.

Since the inception of Core2, my idea and plan has been that LogAppendTime should be the only canonical source of time. The main argument is that it should be easy to reason about what's happening, and to never introduce any implicit sources of time anywhere in the system.

1. CURRENT_TIMESTAMP, CURRENT_TIME and CURRENT_DATE are derived from LogAppendTime, called CURRENT_SYSTEM_TIMESTAMP here.
2. The CURRENT_SYSTEM_TIMESTAMP session variable is necessary to set for repeatable reads, as this provides an upper hard limit on what can be seen. Repeatable reads are not expected to be a massive use-case, but should be possible. This sits below the FOR SYSTEM_TIME AS OF family of predicates in SQL:2011 itself. (Drivers will usually guarantee read-your-own-writes within the current session implicitly by waiting for their submitted transactions to be processed, which doesn't require repeatable reads as such, just that the log has advanced enough.)
3. The CURRENT_SYSTEM_TIMESTAMP is really the tx-id in temporal and human readable form, and unique per transaction. (This isn't currently true when using Kafka which has millisecond precision, nor enforced in general.)
4. An option is to have CURRENT_MAX_VISIBLE_TX_ID instead, and derive CURRENT_TIMESTAMP from this to avoid confusion. This requires less magic, but introduces an opaque transaction id to the end user, which might be a good thing.
5. CURRENT_TIMESTAMP can be seen as a value stored in the database. It doesn't advance on its own: the database isn't a clock. This is initially not intuitive, but a consequence of building an immutable, deterministic database. Queries can only see the state of the database and the parameters provided, nothing else.
6. APPLICATION_TIME can be provided explicitly by the user, for both as read constraints (AS OF, OVERLAPS etc.) and DML (FOR PORTION OF, APPLICATION_TIME_START/END).
7. During basic immutable usage, with some audit and corrections, where the data mainly sits in the past, the above won't really be noticed.
8. When one wants future APPLICATION_TIME data to appear as wall clock time advances, SQL:2011 in DEFAULT_APPLICATION_TIME ISO_MODE already sees this, as it doesn't filter anything. A hint maybe about why this is the default in SQL:2011?
9. When DEFAULT_APPLICATION_TIME AS OF CURRENT_SYSTEM_TIMESTAMP is set, there will be a dependency on a flow of transactions through the system for observable time to advance. When making queries into this potential future, the user can (and probably should) explicitly specify APPLICATION_TIME AS OF ? and provide it as a parameter, originating from an upstream event, or a time oracle like the client's local clock. We don't make any assumptions about this timestamp or when it will advance.
10. DEFAULT_APPLICATION_TIME could also support AS OF ?, which is a terser way of the above, impacting all tables.
11. DEFAULT_APPLICATION_TIME AS OF LOCAL capturing the node's local clock implicitly, seems intuitive, as it makes time advance. The main problem with this the inconsistency with write transactions in the same session. It also creates a coupling between the APPLICATION_TIME one wishes to query at and the LogAppendTime which may or may not exist. If one wants this, one can do it explicitly via a parameter using any of the above methods. Several nodes implicitly and independently advancing APPLICATION_TIME feels like a potential source of confusion and unintentional inconsistency during write transactions, even if it is strictly deterministic. NTP should be used for basic sanity, but not attempted to be relied on.
12. In some cases, submitting a transaction to capture a new and current LogAppendTime to use for the processing may be the right thing to do, and derive some data from this which is stored and potentially later further processed. This might happen via triggers.

== UTC Original Time Zone

All processing has a "original time zone" (as per spec) which is set to UTC. The user can on a per-session basis change this, and of course also insert timestamps with different time zones. CURRENT_DATE, CURRENT_TIME, LOCALTIME and LOCALDATE should be used with care, and with the session time zone set, we may even consider removing these, and only allow literals and explicit casts from CURRENT_TIMESTAMP. Literals are again of course allowed.

The reason for this is that the timezone of the system doesn't represent the timezone(s) that the application operates within. Hence, there's no safe default timezone to assume at the database level. One could of course support system-wide configuration of a different time zone that UTC if this was deemed. In AWS EC2 nodes are set to UTC by default, and this is a bit similar. Without care one can easily get the timezone from the local machine, via the JVM. This choice should always be explicit. Another risk is that different nodes may not have the same timezone, though this is would be very rare in practice.
